# -*- coding: utf-8 -*-
import glob
import cv2
import numpy as np
import glob
import os, io
import json
import pickle
data_root_path = 'C:/Users/minje/PycharmProjects/pytorchproject/VisionAPI/'
save_root_path = 'C:/Users/minje/PycharmProjects/pytorchproject/VisionAPI/images/'
json_root_path = 'C:/Users/minje/PycharmProjects/pytorchproject/VisionAPI/Gvidatas/'
temp = []
temp = os.listdir(json_root_path)
temp_len=len(os.listdir('C:/Users/minje/PycharmProjects/pytorchproject/VisionAPI/images/all_images/'))-1
textlist =[]
def detect_text(path):
    from google.cloud import vision
    client = vision.ImageAnnotatorClient()

    with io.open(path, 'rb') as image_file:
        content = image_file.read()

    image = vision.Image(content=content)

    response = client.text_detection(image=image)
    texts = response.text_annotations
    for text in texts:
        textbox = ('\n"{}"'.format(text.description))
        textbox = textbox.split('\n')
        textlist.append(textbox)
        save_textlist = textlist[0]
        #print(save_textlist)
        with open('save_textlist.pkl','wb')as f:
            pickle.dump(save_textlist,f)


with open('save_textlist.pkl', 'rb') as f:
    jsonlist = pickle.load(f)

    for k in range (2,len(temp)-1):
        with open(json_root_path +f'Gvidata{k}.json','r',encoding='UTF8') as file:
            json_data = json.load(file)
            json_data['text'] = jsonlist[k]

            print(json.dump(json_data, open(json_root_path + f'Gvidata{k}.json', 'w')))



        #print(('\n"{}"'.format(text.description)))
        #vertices = (['({},{})'.format(vertex.x, vertex.y)
        #           for vertex in text.bounding_poly.vertices])

        #print('bounds: {}'.format(','.join(vertices)))

        #with open("textdata.txt", 'a') as f:
        #    f.write(textbox)


images= glob.glob(save_root_path +'/all_images/*.jpg')

for text_images in images:
    file_name = os.path.join(os.path.dirname(__file__),text_images)
    detect_text(file_name)

